{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Currently editing on the plane."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## GPX data recorded during an early morning Southwest Flight from Fort Lauderdale to New Orleans\n", "\n", "## [Interact with this notebook on Binder ](https://mybinder.org/v2/gh/dm-wyncode/zipped-iterables-binder-notebooks/master).\n", "\n", "### Resources\n", "\n", "* [Map Plus iOS application](http://duweis.com/en/mapplus.html)\n", "* [Pandas](https://pandas.pydata.org/pandas-docs/version/0.23.4/index.html)\n", "* [Minio](https://github.com/minio/minio): a high performance object storage server compatible with Amazon S3 APIs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load the data from a [Minio](https://github.com/minio/minio) instance I have deployed."]}, {"cell_type": "code", "execution_count": 144, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[b'<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\" ?>', b'<gpx xmlns=\"http://www.topografix.com/GPX/1/1\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:gpx_style=\"http://www.topografix.com/GPX/gpx_style/0/2\" xsi:schemaLocation=\"http://www.topografix.com/GPX/1/1 http://www.topografix.com/GPX/1/1/gpx.xsd http://www.topografix.com/GPX/gpx_style/0/2 http://www.topografix.com/GPX/gpx_style/0/2/gpx_style.xsd\" version=\"1.1\" creator=\"Map Plus 2.8.7.1\">', b'  <metadata>', b'    <link href=\"http://www.duweis.com\">', b'      <text>Map Plus</text>', b'    </link>', b'    <time>2019-10-17T12:33:03Z</time>', b'  </metadata>', b'', b'  <trk>']\n"]}], "source": ["import urllib.request\n", "import itertools as it\n", "from pprint import pprint\n", "from functools import partial, reduce\n", "import operator as op\n", "\n", "# Define configured pprint suitable for notebooks\n", "pprint_ = partial(pprint, indent=4)\n", "\n", "\n", "def dhead(d: dict, n=5):\n", "    \"\"\"Return the first n items from a dictionary.\"\"\"\n", "    return {k: v for k, v in it.islice(d.items(), 0, n)}\n", "\n", "\n", "with urllib.request.urlopen(\n", "    \"https://minio.apps.selfip.com/mymedia/gpx/fort_lauderdale__to__new_orleans.gpx\"\n", ") as res:\n", "    data = res.read()\n", "\n", "print(data.splitlines()[:10])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Parse the GPX file"]}, {"cell_type": "code", "execution_count": 145, "metadata": {}, "outputs": [], "source": ["from lxml import etree"]}, {"cell_type": "code", "execution_count": 146, "metadata": {}, "outputs": [], "source": ["tree = etree.fromstring(data, etree.XMLParser())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Display set of tags"]}, {"cell_type": "code", "execution_count": 147, "metadata": {}, "outputs": [{"data": {"text/plain": ["{'{http://www.topografix.com/GPX/1/1}cmt',\n", " '{http://www.topografix.com/GPX/1/1}ele',\n", " '{http://www.topografix.com/GPX/1/1}extensions',\n", " '{http://www.topografix.com/GPX/1/1}gpx',\n", " '{http://www.topografix.com/GPX/1/1}link',\n", " '{http://www.topografix.com/GPX/1/1}metadata',\n", " '{http://www.topografix.com/GPX/1/1}name',\n", " '{http://www.topografix.com/GPX/1/1}text',\n", " '{http://www.topografix.com/GPX/1/1}time',\n", " '{http://www.topografix.com/GPX/1/1}trk',\n", " '{http://www.topografix.com/GPX/1/1}trkpt',\n", " '{http://www.topografix.com/GPX/1/1}trkseg',\n", " '{http://www.topografix.com/GPX/gpx_style/0/2}color',\n", " '{http://www.topografix.com/GPX/gpx_style/0/2}line',\n", " '{http://www.topografix.com/GPX/gpx_style/0/2}width'}"]}, "execution_count": 147, "metadata": {}, "output_type": "execute_result"}], "source": ["{element.tag for element in tree.iter()}"]}, {"cell_type": "code", "execution_count": 149, "metadata": {}, "outputs": [{"data": {"text/plain": ["False"]}, "execution_count": 149, "metadata": {}, "output_type": "execute_result"}], "source": ["set(tree.iterchildren()) == set(tree.iter())"]}, {"cell_type": "code", "execution_count": 153, "metadata": {}, "outputs": [], "source": ["meta, trk, = tree.iterchildren()"]}, {"cell_type": "code", "execution_count": 160, "metadata": {}, "outputs": [], "source": ["*_, trkseg = trk.iterchildren()"]}, {"cell_type": "code", "execution_count": 162, "metadata": {}, "outputs": [], "source": ["data_points = list(trkseg.iter())"]}, {"cell_type": "code", "execution_count": 166, "metadata": {}, "outputs": [], "source": ["tags = {item.tag for item in data_points}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## There is 1 trkseg element. It may be the root of all the location points."]}, {"cell_type": "code", "execution_count": 171, "metadata": {}, "outputs": [{"data": {"text/plain": ["[('{http://www.topografix.com/GPX/1/1}ele', 1824),\n", " ('{http://www.topografix.com/GPX/1/1}time', 1829),\n", " ('{http://www.topografix.com/GPX/1/1}trkpt', 1829),\n", " ('{http://www.topografix.com/GPX/1/1}trkseg', 1)]"]}, "execution_count": 171, "metadata": {}, "output_type": "execute_result"}], "source": ["[(tag, len([element for element in data_points if element.tag == tag])) for tag in tags]"]}, {"cell_type": "code", "execution_count": 211, "metadata": {}, "outputs": [], "source": ["trkpnt_children = list(trkseg.iterchildren())"]}, {"cell_type": "code", "execution_count": 226, "metadata": {}, "outputs": [], "source": ["from collections import namedtuple"]}, {"cell_type": "code", "execution_count": 244, "metadata": {}, "outputs": [], "source": ["TrackPoint = namedtuple('TrackPoint', ('coordinate', 'ele', 'time'))"]}, {"cell_type": "code", "execution_count": 273, "metadata": {}, "outputs": [], "source": ["trkpnts_ = (\n", "    ((element.attrib,), tuple(e.text for e in element.iterdescendants()))\n", "    for element in trkpnt_children\n", ")\n", "\n", "trkpnts = [tuple(it.chain(*item)) for item in trkpnts_]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Not all items have a all three of  `('coordinate', 'ele', 'time')`"]}, {"cell_type": "code", "execution_count": 274, "metadata": {}, "outputs": [{"data": {"text/plain": ["{2, 3}"]}, "execution_count": 274, "metadata": {}, "output_type": "execute_result"}], "source": ["{len(items) for items in trkpnts}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## See what is missing in those with only 2 parts."]}, {"cell_type": "code", "execution_count": 275, "metadata": {}, "outputs": [{"data": {"text/plain": ["[({'lat': '26.07364077867658', 'lon': '-80.13974719286466'},\n", "  '2019-10-17T10:32:23Z'),\n", " ({'lat': '26.07330806773481', 'lon': '-80.13861468216476'},\n", "  '2019-10-17T10:32:44Z'),\n", " ({'lat': '26.07329140328246', 'lon': '-80.13861683228613'},\n", "  '2019-10-17T10:33:09Z'),\n", " ({'lat': '26.07358034244973', 'lon': '-80.13865072072218'},\n", "  '2019-10-17T10:34:37Z'),\n", " ({'lat': '26.07370411580322', 'lon': '-80.14069088505309'},\n", "  '2019-10-17T10:34:46Z')]"]}, "execution_count": 275, "metadata": {}, "output_type": "execute_result"}], "source": ["[items for items in trkpnts if len(items) == 2]"]}, {"cell_type": "code", "execution_count": 276, "metadata": {}, "outputs": [{"data": {"text/plain": ["[({'lat': '26.07408333333334', 'lon': '-80.136275'},\n", "  '14',\n", "  '2019-10-17T10:16:44Z'),\n", " ({'lat': '26.07371', 'lon': '-80.13643666666667'},\n", "  '5.8',\n", "  '2019-10-17T10:16:52Z'),\n", " ({'lat': '26.07379666666666', 'lon': '-80.13646999999999'},\n", "  '1.1',\n", "  '2019-10-17T10:17:24Z'),\n", " ({'lat': '26.07390333333334', 'lon': '-80.13640000000001'},\n", "  '5.3',\n", "  '2019-10-17T10:17:47Z'),\n", " ({'lat': '26.07400833333334', 'lon': '-80.13633'},\n", "  '5.9',\n", "  '2019-10-17T10:18:32Z')]"]}, "execution_count": 276, "metadata": {}, "output_type": "execute_result"}], "source": ["[items for items in trkpnts if len(items) == 3][:5]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Rewrite the comprehensions to account for a lack of `ele` in a trkpnt."]}, {"cell_type": "code", "execution_count": 285, "metadata": {}, "outputs": [], "source": ["def trkpnt_handler(trkpnt):\n", "    \"\"\"Insert a None if there is no ele data point.\"\"\"\n", "    length = len(trkpnt)\n", "    assert length in range(1, 3), f\"Length is {length}: {trkpnt}\"\n", "    try:\n", "        ele, datetime = trkpnt\n", "    except ValueError:\n", "        datetime, = trkpnt\n", "        ele = None\n", "    return ele, datetime"]}, {"cell_type": "code", "execution_count": 286, "metadata": {}, "outputs": [], "source": ["trkpnts_ = (\n", "    (\n", "        (element.attrib, ),\n", "        trkpnt_handler(tuple(e.text for e in element.iterdescendants())),\n", "    )\n", "    for element in trkpnt_children\n", ")\n", "\n", "trkpnts = [tuple(it.chain(*item)) for item in trkpnts_]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Begin copied cells below from another post."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Practice laziness in the sense of one of the [Three Virtues](http://threevirtues.com/): laziness, impatience, hubris\n", "\n", "### Issues\n", "\n", "1. I don't like having to retype strings that are `dict` keys. It's error-prone and taxes my memory. I would prefer a variable that I didn't have to manually define.   \n", "Use `Enum` to create variables programatically. A plain `dict` would probably work, too. I like the way that an `Enum` is represented in output and it's `type` feature. And I am trying to find use cases for an `Enum`."]}, {"cell_type": "code", "execution_count": 99, "metadata": {}, "outputs": [{"data": {"text/plain": ["('foo', {'FOO': 'foo'})"]}, "execution_count": 99, "metadata": {}, "output_type": "execute_result"}], "source": ["example = dict(FOO=\"foo\")\n", "globals().update(example)\n", "FOO, example"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Walk the data structure to get all the keys.\n", "\n", "I wrote this function as an inspiration from the Stack Overflow question [Access nested dictionary items via a list of keys?](https://stackoverflow.com/q/14692690/1913726)"]}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [], "source": ["def paths_in_data(data: dict, parent=()):\n", "    \"\"\"Calculate keys and/or indices in a nested dict.\"\"\"\n", "\n", "    if not any(isinstance(data, type_) for type_ in (dict, list, tuple)):\n", "        return (parent,)\n", "    else:\n", "        try:  # Handle dict\n", "            return reduce(\n", "                op.add,\n", "                (paths_in_data(v, op.add(parent, (k,))) for k, v in data.items()),\n", "                (),\n", "            )\n", "        except AttributeError:  # Handle indexable sequences.\n", "            return reduce(\n", "                op.add,\n", "                (paths_in_data(v, op.add(parent, (data.index(v),))) for v in data),\n", "                (),\n", "            )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Truncated example of the paths generated from `paths_in_data`."]}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [{"data": {"text/plain": ["[('type',),\n", " ('crs', 'type'),\n", " ('crs', 'properties', 'name'),\n", " ('features', 0, 'type'),\n", " ('features', 0, 'properties', 'GUID'),\n", " ('features', 0, 'properties', 'LABEL_EXPR'),\n", " ('features', 0, 'properties', 'TITLE'),\n", " ('features', 0, 'properties', 'LABEL_TEXT'),\n", " ('features', 0, 'properties', 'NOTES'),\n", " ('features', 0, 'geometry', 'type'),\n", " ('features', 0, 'geometry', 'coordinates', 0, 0),\n", " ('features', 0, 'geometry', 'coordinates', 0, 1)]"]}, "execution_count": 32, "metadata": {}, "output_type": "execute_result"}], "source": ["[path for path in it.takewhile(lambda x: x[-1] != 2, paths_in_data(data))]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Get a set of all the keys."]}, {"cell_type": "code", "execution_count": 44, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[   'GUID',\n", "    'LABEL_EXPR',\n", "    'LABEL_TEXT',\n", "    'NOTES',\n", "    'TITLE',\n", "    'coordinates',\n", "    'crs',\n", "    'features',\n", "    'geometry',\n", "    'name',\n", "    'properties',\n", "    'type']\n"]}], "source": ["data_key_set = sorted(\n", "    {key for key in it.chain.from_iterable(paths_in_data(data)) if isinstance(key, str)}\n", ")\n", "_print(data_key_set)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Cast `data_key_set` into valid variable names"]}, {"cell_type": "code", "execution_count": 47, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[   'GUID',\n", "    'LABEL_EXPR',\n", "    'LABEL_TEXT',\n", "    'NOTES',\n", "    'TITLE',\n", "    'COORDINATES',\n", "    'CRS',\n", "    'FEATURES',\n", "    'GEOMETRY',\n", "    'NAME',\n", "    'PROPERTIES',\n", "    'TYPE']\n"]}], "source": ["from string import digits, whitespace, punctuation\n", "\n", "# Transform all whitespace and punctuation into underscores\n", "# Not needed but left here as an example\n", "translation = str.maketrans(dict(zip((*whitespace, *punctuation), it.cycle(\"_\"))))\n", "\n", "data_key_set_names = [\n", "    key.translate(translation).strip(digits).upper() for key in data_key_set\n", "]\n", "_print(data_key_set_names)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Define an `Enum` using the [functional API](https://docs.python.org/3/library/enum.html#functional-api).\n"]}, {"cell_type": "code", "execution_count": 50, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["mappingproxy({   'COORDINATES': <DataKeys.COORDINATES: 'coordinates'>,\n", "                 'CRS': <DataKeys.CRS: 'crs'>,\n", "                 'FEATURES': <DataKeys.FEATURES: 'features'>,\n", "                 'GEOMETRY': <DataKeys.GEOMETRY: 'geometry'>,\n", "                 'GUID': <DataKeys.GUID: 'GUID'>,\n", "                 'LABEL_EXPR': <DataKeys.LABEL_EXPR: 'LABEL_EXPR'>,\n", "                 'LABEL_TEXT': <DataKeys.LABEL_TEXT: 'LABEL_TEXT'>,\n", "                 'NAME': <DataKeys.NAME: 'name'>,\n", "                 'NOTES': <DataKeys.NOTES: 'NOTES'>,\n", "                 'PROPERTIES': <DataKeys.PROPERTIES: 'properties'>,\n", "                 'TITLE': <DataKeys.TITLE: 'TITLE'>,\n", "                 'TYPE': <DataKeys.TYPE: 'type'>})\n"]}], "source": ["from enum import Enum\n", "\n", "DataKeys = Enum(\"DataKeys\", type=str, names=zip(data_key_set_names, data_key_set))\n", "_print(DataKeys.__members__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Add names from `DataKeys` to global namespace."]}, {"cell_type": "code", "execution_count": 51, "metadata": {}, "outputs": [], "source": ["globals().update(DataKeys.__members__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Inspect a variable"]}, {"cell_type": "code", "execution_count": 70, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["(<DataKeys.FEATURES: 'features'>, <enum 'DataKeys'>, True)\n"]}], "source": ["_print((FEATURES, type(FEATURES), isinstance(FEATURES, str)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Get some specific data"]}, {"cell_type": "code", "execution_count": 71, "metadata": {}, "outputs": [], "source": ["def get_from(data, path):\n", "    \"\"\"Get a leaf from iterable of keys and/or indices.\n", "    \n", "    :data: Collection where nodes are either a dict or list.\n", "    :path: Collection of keys and/or indices leading to a leaf.\n", "    \"\"\"\n", "    return reduce(op.getitem, path, data)"]}, {"cell_type": "code", "execution_count": 76, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["'FeatureCollection'\n", "'name'\n", "'urn:ogc:def:crs:OGC:1.3:CRS84'\n", "25.80153849443961\n"]}], "source": ["paths = [\n", "    (TYPE,),\n", "    (CRS, TYPE),\n", "    (CRS, PROPERTIES, NAME),\n", "    (FEATURES, 0, GEOMETRY, COORDINATES, 0, 1),\n", "]\n", "\n", "for path in paths:\n", "    _print(get_from(data, path))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## View in Pandas DataFrame"]}, {"cell_type": "code", "execution_count": 93, "metadata": {}, "outputs": [], "source": ["names = \"lon lat ele\".split()\n", "\n", "\n", "class PandasColumn(Enum):\n", "    \"\"\"Extend Enum so that when a member is used as a Pandas data frame column its value is displayed.\"\"\"\n", "\n", "    def __str__(self):\n", "        return self.value\n", "\n", "\n", "CoordinateColumns = PandasColumn(\n", "    \"CoordinateColumn\", type=str, names=zip((name.upper() for name in names), names)\n", ")\n", "globals().update(CoordinateColumns.__members__)"]}, {"cell_type": "code", "execution_count": 94, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>lon</th>\n", "      <th>lat</th>\n", "      <th>ele</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <td>0</td>\n", "      <td>-80.203793</td>\n", "      <td>25.801538</td>\n", "      <td>-0.058535</td>\n", "    </tr>\n", "    <tr>\n", "      <td>1</td>\n", "      <td>-80.203824</td>\n", "      <td>25.801507</td>\n", "      <td>10.088560</td>\n", "    </tr>\n", "    <tr>\n", "      <td>2</td>\n", "      <td>-80.203784</td>\n", "      <td>25.801589</td>\n", "      <td>11.503721</td>\n", "    </tr>\n", "    <tr>\n", "      <td>3</td>\n", "      <td>-80.203711</td>\n", "      <td>25.801508</td>\n", "      <td>9.746153</td>\n", "    </tr>\n", "    <tr>\n", "      <td>4</td>\n", "      <td>-80.203605</td>\n", "      <td>25.801513</td>\n", "      <td>9.274504</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["         lon        lat        ele\n", "0 -80.203793  25.801538  -0.058535\n", "1 -80.203824  25.801507  10.088560\n", "2 -80.203784  25.801589  11.503721\n", "3 -80.203711  25.801508   9.746153\n", "4 -80.203605  25.801513   9.274504"]}, "execution_count": 94, "metadata": {}, "output_type": "execute_result"}], "source": ["import pandas as pd\n", "\n", "df = pd.DataFrame(\n", "    get_from(data, (FEATURES, 0, GEOMETRY, COORDINATES)),\n", "    columns=CoordinateColumns.__members__.values(),\n", ")\n", "df.head()"]}, {"cell_type": "code", "execution_count": 90, "metadata": {}, "outputs": [{"data": {"text/plain": ["0       25.801538\n", "1       25.801507\n", "2       25.801589\n", "3       25.801508\n", "4       25.801513\n", "          ...    \n", "1102    26.119918\n", "1103    26.119874\n", "1104    26.119792\n", "1105    26.119739\n", "1106    26.119739\n", "Name: CoordinateColumn.LAT, Length: 1107, dtype: float64"]}, "execution_count": 90, "metadata": {}, "output_type": "execute_result"}], "source": ["df[LAT]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Conclusions\n", "\n", "I was hoping that there would be some time information in the GeoJSON data.\n", "\n", "After exploring the export options in Map Plus, I discovered an XML format that includes times. This will be more interesting.\n", "\n", "The GeoJSON is adequate for longitude, latitude and elevation data. TODO: Display GeoJSON data in a Jupyter notebook.\n", "\n", "### GPX formatted data for same trip.\n", "\n", "```xml\n", "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\" ?>\n", "<gpx xmlns=\"http://www.topografix.com/GPX/1/1\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:gpx_style=\"http://www.topografix.com/GPX/gpx_style/0/2\" xsi:schemaLocation=\"http://www.topografix.com/GPX/1/1 http://www.topografix.com/GPX/1/1/gpx.xsd http://www.topografix.com/GPX/gpx_style/0/2 http://www.topografix.com/GPX/gpx_style/0/2/gpx_style.xsd\" version=\"1.1\" creator=\"Map Plus 2.8.6.2\">\n", "  <metadata>\n", "    <link href=\"http://www.duweis.com\">\n", "      <text>Map Plus</text>\n", "    </link>\n", "    <time>2019-10-09T15:18:41Z</time>\n", "  </metadata>\n", "\n", "  <trk>\n", "    <name>10/8/19</name>\n", "    <cmt>50 km, 1 h 29 min</cmt>\n", "    <extensions>\n", "      <gpx_style:line>\n", "        <gpx_style:color>ff7a00</gpx_style:color>\n", "        <gpx_style:width>4000</gpx_style:width>\n", "      </gpx_style:line>\n", "    </extensions>\n", "    <trkseg>\n", "      <trkpt lat=\"25.80153849443961\" lon=\"-80.20379332833011\">\n", "        <ele>-0.05853462</ele>\n", "        <time>2019-10-09T00:55:50Z</time>\n", "      </trkpt>\n", "      <trkpt lat=\"25.80150727185029\" lon=\"-80.20382425755281\">\n", "        <ele>10.08856</ele>\n", "        <time>2019-10-09T00:55:54Z</time>\n", "      </trkpt>\n", "\n", "```"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.0b4"}, "nikola": {"category": "", "date": "2019-10-18 15:40:02 UTC", "description": "Analyze GPX data recorded with Map Plus iOS application during a flight from Fort Lauderdale to New Orleans.", "link": "", "previewimage": "http://bit.ly/2oAdgS5", "slug": "analyze-gpx-data-recorded-during-a-flight-from-fort-lauderdale-to-new-orleans", "tags": "data, gpx, python, code, pandas", "title": "Analyze GPX Data Recorded During A Flight from Fort Lauderdale to New Orleans", "type": "text"}}, "nbformat": 4, "nbformat_minor": 2}