{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Stack Overflow solution\n", "\n", "* Question: [Extract a content from `<a href=\u201cdata:text/csv;\u2026content>`](https://stackoverflow.com/q/58616135/1913726)\n", "* Answer: [My Answer](https://stackoverflow.com/a/58616865/1913726)\n", "\n", "Initially my first thought was that this question on Stack Overflow was dump because anybody can split strings to get wanted data. I consider it a hack though if the data has a scheme and could be parsed by a proper parser.\n", "\n", "The poser of the question changed the question to clarify that he wanted ~~pure python~~ a proper parser for URL data. I'm happy he did because I learned something new. I have been creating the data URLs to embed into a website by joining strings. \n", "\n", "Now I know better.\n", "\n", "It turns out there is a parser and its a well-defined scheme for data URLs. Usually when I think \"this is ~~dumb~~ anti-pattern\" I then do some research and learn something along the way. Though some things do remain dumb and knowing which ones are still ~~dumb~~ anti-pattern is a skill, too.\n", "\n", "For example, [trying to parse HTML with regular expressions](https://stackoverflow.com/a/1732454/1913726) is ~~dumb~~ anti-pattern.\n", "\n", "## Resources\n", "\n", "* [data URLs on MDN](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URIs)\n", "* [python-datauri](https://pypi.org/project/python-datauri/)"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["html_string = \"\"\"\n", "<a href=\"data:text/csv;charset=UTF-8,%22csvcontentfollows\">\n", "\"\"\""]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[{'mimetype': 'text/csv', 'charset': 'UTF-8', 'is_base64': False, 'data': '\"csvcontentfollows'}]\n"]}], "source": ["import lxml.etree\n", "from datauri import DataURI\n", "\n", "tree = lxml.etree.fromstring(html_string, lxml.etree.HTMLParser())\n", "\n", "uris = (\n", "    DataURI(item.attrib[\"href\"])\n", "    for item in tree.iterdescendants()\n", "    if item.attrib.get(\"href\")\n", ")\n", "attrs = (\"mimetype\", \"charset\", \"is_base64\", \"data\")\n", "print([{attr: getattr(uri, attr) for attr in attrs} for uri in uris])"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[{'mimetype': 'text/csv', 'charset': 'UTF-8', 'is_base64': False, 'data': '\"csvcontentfollows'}]\n"]}], "source": ["from html.parser import HTMLParser\n", "from datauri import DataURI\n", "\n", "uri_attrs = (\"mimetype\", \"charset\", \"is_base64\", \"data\")\n", "\n", "class MyHTMLParser(HTMLParser):\n", "    \n", "    def __init__(self):\n", "        super().__init__()\n", "        self.data = []\n", "    \n", "    def handle_starttag(self, tag, attrs):\n", "        if tag == \"a\":\n", "            for attr, value in attrs:\n", "                if attr == \"href\":\n", "                    # Adjust the delimter for splitting as necessary\n", "                    for key, value in attrs:\n", "                        uri = DataURI(value)\n", "                        self.data.append({attr: getattr(uri, attr) for attr in uri_attrs})\n", "        \n", "parser = MyHTMLParser()\n", "parser.feed(html_string)\n", "print(parser.data)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.2"}, "nikola": {"category": "Stack Overflow Solutions", "date": "2019-10-30 14:04:10 UTC", "description": "Extract CSV data from href in a tag in HTML.", "link": "", "slug": "extract-content-from-an-href-tag-in-html-using-python", "tags": "python, code, lxml, stackoverflow", "title": "Extract Content from an href Tag in HTML using Python", "type": "text"}}, "nbformat": 4, "nbformat_minor": 2}